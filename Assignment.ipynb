{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2df9be9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
       "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA2001 Assignment\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
    "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5ef8f",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58fa07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text, types\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import geoalchemy2\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict['host']\n",
    "        db_user    = db_conn_dict['user']\n",
    "        db_pw      = db_conn_dict['password']\n",
    "        default_db = db_conn_dict['user']\n",
    "        port       = db_conn_dict['port']\n",
    "        try:\n",
    "            db = create_engine(f'postgresql+psycopg2://{db_user}:{db_pw}@{host}:{port}/{default_db}', echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn\n",
    "\n",
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(text(sqlcmd), args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d659d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.CursorResult at 0x124b35320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db, conn = pgconnect(credentials)\n",
    "conn.execute(text(\"set search_path to public\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd73b5",
   "metadata": {},
   "source": [
    "### Loading Data into Python from .csv, .txt and .shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a17e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "\n",
    "population_df = pd.read_csv(f\"{data_path}/Population.csv\")\n",
    "businesses_df = pd.read_csv(f\"{data_path}/Businesses.csv\")\n",
    "income_df = pd.read_csv(f\"{data_path}/sa2_income.csv\")\n",
    "postcode_df = pd.read_csv(f\"{data_path}/sa2_postcode.csv\")\n",
    "stops_df = pd.read_csv(f\"{data_path}/Stops.txt\")\n",
    "\n",
    "sa2_gdf = gpd.read_file(f\"{data_path}/SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp\")\n",
    "primary_catchments = gpd.read_file(f\"{data_path}/catchments/catchments_primary.shp\")\n",
    "secondary_catchments = gpd.read_file(f\"{data_path}/catchments/catchments_secondary.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788b6c2",
   "metadata": {},
   "source": [
    "### Data cleaning before ingestion into database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3581bcc",
   "metadata": {},
   "source": [
    "### Cleaning population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c310753",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_population_df = population_df.copy()\n",
    "\n",
    "cleaned_population_df.columns = (\n",
    "    cleaned_population_df.columns\n",
    "    .str.lower()\n",
    "    .str.replace('-', '_')\n",
    "    .str.replace(' ', '_')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9c13f",
   "metadata": {},
   "source": [
    "### Cleaning Businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692ae39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_businesses_df = businesses_df.copy()\n",
    "for col in cleaned_businesses_df.select_dtypes(include=\"object\"):\n",
    "    cleaned_businesses_df[col] = cleaned_businesses_df[col].str.strip()\n",
    "cleaned_businesses_df.rename(columns={\n",
    "    \"0_to_50k_businesses\": \"b_0_50k\",\n",
    "    \"50k_to_200k_businesses\": \"b_50k_200k\",\n",
    "    \"200k_to_2m_businesses\": \"b_200k_2m\",\n",
    "    \"2m_to_5m_businesses\": \"b_2m_5m\",\n",
    "    \"5m_to_10m_businesses\": \"b_5m_10m\",\n",
    "    \"10m_or_more_businesses\": \"b_10m_plus\",\n",
    "    \"total_businesses\": \"total\"\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83763501",
   "metadata": {},
   "source": [
    "### Cleaning Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8641fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/0bgjmph51g3fjv7yfs8y17xc0000gn/T/ipykernel_42220/4119000927.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_income_df['income_earners'].fillna(cleaned_income_df['income_earners'].median(), inplace=True)\n",
      "/var/folders/7w/0bgjmph51g3fjv7yfs8y17xc0000gn/T/ipykernel_42220/4119000927.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_income_df['median_income'].fillna(cleaned_income_df['median_income'].median(), inplace=True)\n",
      "/var/folders/7w/0bgjmph51g3fjv7yfs8y17xc0000gn/T/ipykernel_42220/4119000927.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_income_df['mean_income'].fillna(cleaned_income_df['mean_income'].median(), inplace=True)\n",
      "/var/folders/7w/0bgjmph51g3fjv7yfs8y17xc0000gn/T/ipykernel_42220/4119000927.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_income_df['gini_coefficient'].fillna(cleaned_income_df['gini_coefficient'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cleaned_income_df = income_df.copy()\n",
    "\n",
    "cleaned_income_df.rename(columns={\n",
    "    \"SA2_code\": \"sa2_code\",\n",
    "    \"SA2_name\": \"sa2_name\"\n",
    "}, inplace=True)\n",
    "cleaned_income_df['income_earners'].fillna(cleaned_income_df['income_earners'].median(), inplace=True)\n",
    "cleaned_income_df['median_income'].fillna(cleaned_income_df['median_income'].median(), inplace=True)\n",
    "cleaned_income_df['mean_income'].fillna(cleaned_income_df['mean_income'].median(), inplace=True)\n",
    "cleaned_income_df['gini_coefficient'].fillna(cleaned_income_df['gini_coefficient'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a1f9e",
   "metadata": {},
   "source": [
    "### Cleaning Postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736a231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_postcode_df = postcode_df.copy()\n",
    "\n",
    "postcode_df.rename(columns={\n",
    "    \"SA2_code\": \"sa2_code\",\n",
    "    \"SA2_name\": \"sa2_name\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fb372",
   "metadata": {},
   "source": [
    "### Cleaning Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a4e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_stops_df = stops_df.copy()\n",
    "\n",
    "cleaned_stops_df.columns = cleaned_stops_df.columns.str.strip().str.lower()\n",
    "\n",
    "for col in cleaned_stops_df.select_dtypes(include='object'):\n",
    "    cleaned_stops_df[col] = cleaned_stops_df[col].str.strip()\n",
    "\n",
    "cleaned_stops_df.drop(columns=['parent_station', 'stop_code', 'platform_code', 'location_type'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c393e",
   "metadata": {},
   "source": [
    "### Cleaning Geodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44cdfd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2098 entries, 0 to 2097\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   school_id    2098 non-null   object  \n",
      " 1   catch_type   2098 non-null   object  \n",
      " 2   school_name  2098 non-null   object  \n",
      " 3   add_date     1707 non-null   object  \n",
      " 4   geom         2098 non-null   geometry\n",
      "dtypes: geometry(1), object(4)\n",
      "memory usage: 82.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def clean_gdf(gdf):\n",
    "    gdf = gdf.copy()\n",
    "    gdf.columns = gdf.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "\n",
    "    for col in gdf.select_dtypes(include=\"object\"):\n",
    "        gdf[col] = gdf[col].str.strip()\n",
    "\n",
    "    return gdf\n",
    "\n",
    "cleaned_sa2_gdf = clean_gdf(sa2_gdf)\n",
    "cleaned_primary_catchment= clean_gdf(primary_catchments)\n",
    "cleaned_secondary_catchment = clean_gdf(secondary_catchments)\n",
    "\n",
    "target_crs = \"EPSG:4326\"\n",
    "cleaned_sa2_gdf = cleaned_sa2_gdf.to_crs(target_crs)\n",
    "cleaned_primary_catchment = cleaned_primary_catchment.to_crs(target_crs)\n",
    "cleaned_secondary_catchment = cleaned_secondary_catchment.to_crs(target_crs)\n",
    "\n",
    "cleaned_school_catchment = pd.concat([cleaned_primary_catchment, cleaned_secondary_catchment], ignore_index=True)\n",
    "cleaned_school_catchment.drop(columns=[\n",
    "    \"kindergart\", \"year1\", \"year2\", \"year3\", \"year4\", \"year5\", \"year6\",\n",
    "    \"year7\", \"year8\", \"year9\", \"year10\", \"year11\", \"year12\", \"priority\"\n",
    "], inplace=True)\n",
    "cleaned_school_catchment.rename(columns={\n",
    "    \"use_id\": \"school_id\",\n",
    "    \"use_desc\": \"school_name\",\n",
    "    \"geometry\": \"geom\"  \n",
    "}, inplace=True)\n",
    "print(cleaned_school_catchment.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b6353",
   "metadata": {},
   "source": [
    "### Load in Geodata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b6446",
   "metadata": {},
   "source": [
    "### 1.2. Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0fdae8",
   "metadata": {},
   "source": [
    "We now need to ingest all of the collected data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa354eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS population CASCADE;\n",
    "CREATE TABLE population (\n",
    "    sa2_code BIGINT PRIMARY KEY,\n",
    "    sa2_name TEXT,\n",
    "    \"0_4_people\" INTEGER,\n",
    "    \"5_9_people\" INTEGER,\n",
    "    \"10_14_people\" INTEGER,\n",
    "    \"15_19_people\" INTEGER,\n",
    "    \"20_24_people\" INTEGER,\n",
    "    \"25_29_people\" INTEGER,\n",
    "    \"30_34_people\" INTEGER,\n",
    "    \"35_39_people\" INTEGER,\n",
    "    \"40_44_people\" INTEGER,\n",
    "    \"45_49_people\" INTEGER,\n",
    "    \"50_54_people\" INTEGER,\n",
    "    \"55_59_people\" INTEGER,\n",
    "    \"60_64_people\" INTEGER,\n",
    "    \"65_69_people\" INTEGER,\n",
    "    \"70_74_people\" INTEGER,\n",
    "    \"75_79_people\" INTEGER,\n",
    "    \"80_84_people\" INTEGER,\n",
    "    \"85_and_over_people\" INTEGER,\n",
    "    total_people INTEGER\n",
    ");\n",
    "                  \n",
    "DROP TABLE IF EXISTS businesses CASCADE;\n",
    "CREATE TABLE businesses (\n",
    "    industry_code TEXT,\n",
    "    industry_name TEXT,\n",
    "    sa2_code BIGINT,\n",
    "    sa2_name TEXT,\n",
    "    b_0_50k INTEGER,\n",
    "    b_50k_200k INTEGER,\n",
    "    b_200k_2m INTEGER,\n",
    "    b_2m_5m INTEGER,\n",
    "    b_5m_10m INTEGER,\n",
    "    b_10m_plus INTEGER,\n",
    "    total INTEGER,\n",
    "    PRIMARY KEY (sa2_code, industry_code)\n",
    "\n",
    ");\n",
    "                  \n",
    "DROP TABLE IF EXISTS income CASCADE;\n",
    "CREATE TABLE income (\n",
    "    sa2_code BIGINT PRIMARY KEY,\n",
    "    sa2_name TEXT,\n",
    "    income_earners FLOAT,\n",
    "    median_income FLOAT,\n",
    "    mean_income FLOAT,\n",
    "    gini_coefficient FLOAT\n",
    ");\n",
    "                  \n",
    "DROP TABLE IF EXISTS postcode CASCADE;\n",
    "CREATE TABLE postcode (\n",
    "    postcode INTEGER,\n",
    "    sa2_code BIGINT,\n",
    "    sa2_name TEXT,\n",
    "    PRIMARY KEY (postcode, sa2_code)\n",
    ");\n",
    "                  \n",
    "DROP TABLE IF EXISTS stops CASCADE;\n",
    "CREATE TABLE stops (\n",
    "    stop_id TEXT,\n",
    "    stop_name TEXT,\n",
    "    stop_lat FLOAT,\n",
    "    stop_lon FLOAT,\n",
    "    sa2_code BIGINT,\n",
    "    sa2_name TEXT,\n",
    "    sa4_name TEXT,\n",
    "    wheelchair_boarding INTEGER,\n",
    "    geom geometry(Point, 4326)\n",
    ");\n",
    "                  \n",
    "DROP TABLE IF EXISTS sa2_boundaries CASCADE;\n",
    "CREATE TABLE sa2_boundaries (\n",
    "    sa2_code21 TEXT PRIMARY KEY,\n",
    "    sa2_name21 TEXT NOT NULL,\n",
    "    sa4_code21 TEXT,\n",
    "    sa4_name21 TEXT,\n",
    "    areasqkm21 DOUBLE PRECISION,\n",
    "    geom geometry(MultiPolygon, 4326)\n",
    ");\n",
    "                  \n",
    "DROP TABLE IF EXISTS school_catchments CASCADE;\n",
    "CREATE TABLE school_catchments (\n",
    "    school_id TEXT PRIMARY KEY,\n",
    "    catch_type TEXT NOT NULL,\n",
    "    school_name TEXT NOT NULL,\n",
    "    add_date DATE,\n",
    "    geom geometry(MultiPolygon, 4326) NOT NULL\n",
    ");\n",
    "                  \n",
    "                  \n",
    "\n",
    "CREATE INDEX idx_catchments_geom ON school_catchments USING GIST (geom);\n",
    "\"\"\"))\n",
    "cleaned_population_df.to_sql(\n",
    "    \"population\",\n",
    "    con=conn,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    method='multi',          \n",
    "    chunksize=1000           \n",
    ")\n",
    "cleaned_businesses_df.to_sql(\n",
    "    \"businesses\",\n",
    "    con=conn,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    method='multi',         \n",
    "    chunksize=1000          \n",
    ")\n",
    "cleaned_income_df.to_sql(\n",
    "    \"income\",\n",
    "    con=conn,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    method='multi',         \n",
    "    chunksize=1000          \n",
    ")\n",
    "cleaned_postcode_df.to_sql(\n",
    "    \"postcodes\",\n",
    "    con=conn,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    method='multi',         \n",
    "    chunksize=1000          \n",
    ")\n",
    "cleaned_stops_df.to_sql(\n",
    "    \"stops\",\n",
    "    con=conn,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    method='multi',         \n",
    "    chunksize=1000          \n",
    ")\n",
    "cleaned_school_catchment.set_geometry(\"geom\", inplace=True)\n",
    "cleaned_sa2_gdf.to_postgis(\"sa2_boundaries\", conn, if_exists=\"replace\", index=False)\n",
    "cleaned_school_catchment.to_postgis(\"school_catchments\", conn, if_exists=\"replace\", index=False)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "81b52a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
